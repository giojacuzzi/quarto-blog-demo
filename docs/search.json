[
  {
    "objectID": "posts/acoustic-indices/index.html",
    "href": "posts/acoustic-indices/index.html",
    "title": "What are acoustic indices?",
    "section": "",
    "text": "Assessing biodiversity with sound."
  },
  {
    "objectID": "posts/acoustic-indices/index.html#if-a-tree-falls-in-the-forest",
    "href": "posts/acoustic-indices/index.html#if-a-tree-falls-in-the-forest",
    "title": "What are acoustic indices?",
    "section": "If a tree falls in the forest…",
    "text": "If a tree falls in the forest…\n…and no one is around to hear it, does it make a sound? Yes, and if you had acoustic monitors deployed at the time, you could hear it! Soundscape ecology, the study of environmental sound, is a burgeoning field of research. By listening closely to the vocalizations and activity of wildlife, we can gain a unique perspective on the community composition and biodiversity of a place. We do this with passive acoustic monitoring, or in other words, by going out into the field to install a bunch of microphones and record days, months, or even years of audio data. And with increasingly cost-effective microphones and data storage becoming ubiquitous, there has never been a better time to get out there and record.\nBut, speaking of data storage, a full week of constant 24 hour recording can yield more than 50 GB of data (at 44.1 kHz). Considering that may be one site of many, those numbers will scale up fast. With more TB of data and hours of recordings than any human could possibly listen to in their lifetime, how can we efficiently reveal the secrets of our recordings, and understand the biodiversity of our study area?"
  },
  {
    "objectID": "posts/acoustic-indices/index.html#how-do-acoustic-indices-work",
    "href": "posts/acoustic-indices/index.html#how-do-acoustic-indices-work",
    "title": "What are acoustic indices?",
    "section": "How do acoustic indices work?",
    "text": "How do acoustic indices work?\nDifferent acoustic indices combine different elements of sound and different statistical methods to measure complexity. They typically use:\n\nSound intensity (in dB)\nPresence/absence of sound in a frequency band\nPower spectrum\n\nWith these measures, the indices then apply established statitstical methods, such as the Shannon biodiversity index or the Gini inequality index. More than 60 different indices have been devised so far, but lets look at some of the most commonly used ones.\n\nBioacoustic index\nDeveloped by Boelman and team to estimate relative bird abundance in Hawaii. They wanted to look at how non-native plant species invasion affected birds, so they developed this acoustic index and validated it against traditional ornithological surveys that directly measured birds, species, composition, and abundance.\n\n\n\nBioacoustic spectra of avian vocalizations from digital audio recordings, showing sound level intensity from 2000–8000 Hz. Recordings were acquired (a) directly after the dawn chorus (7–9 am local time), and (b) at mid-day (12–2 pm). Bioacoustic indices of avian abundance (Figs. 1, 2c, 3a) were calculated from the morning spectra shown in (a) at the time of day during which birds are most vocal. Forest sites are indicated in blue, woodland sites are indicated in green, savanna sites are shown in red and shrubland sites are indicated by cyan. (Boelman et al 2007)\n\n\nThe bioacoustic index measures the area under the log amplitude spectrum curve in dB by kHz with the maximum dB level set to zero. The blue line is for dawn recordings at a forest site. They chose a range in this example from 2-8kHz because that’s the range of the birds that are singing. The area under the curve is the bioacoustic index. At other sites (different colors), the area under the curve is different. A is for the dawn chorus, and B is midday. Forest sites are blue, woodland green, savannah in red. They found that the bioacoustic index did correlate well with bird abundance overall.\n\n\nNormalized Difference Soundscape Index\nNDSI quantifies disturbance based on the ratio of biotic to anthropogenic sound in recordings. It also uses the area under the curve, but divides the power spectrum into two parts (anthrophony, typically 1-2kHz vs biophony, often 2-8kHz). Kasten and team had a big library of acoustic data and used it to develop the NDSI for efficient analysis.\n\\(NDSI = (biophony - anthrophony) / (biophony + anthrophony)\\)\nValues tending to -1 indicate more anthrophony, while values tending to +1 indicate more biophony. It’s important to understand that there are limitations due to the strict reliance on frequency bin division, but these can be tuned to improve results based on your study site (Gage & Axel 2014).\n\n\nAcoustic Diversity and Acoustic Evenness\nThese two related indices look at occupancy of frequency bins and then apply either the Shannon index for diversity or Gini index for evenness (Pjanowski et al 2011, Villanueva-River et al 2011). They tend to yield inverse results of each other. Both start by dividing the frequency range into different bands, then determine ‘occupancy’ by looking for sounds that are loud enough to pass some threshold. The resulting proportion of active or “occupied” sound in those bands indicate levels of activity.\nThe ADI uses the Shannon to output from zero to the natural log of the number of kHz bins. Larger values indicate more even activity among frequency bins (either noisy across all frequency bands or completely silent), while values closer to zero indicate increasingly narrow or purse tones (i.e. all energy in one frequency band).\n\n\nAcoustic Complexity Index\nACI works in a similar way, but is a bit more complicated (it lives up to its name). This is one of the most widely used indices for measuring biodiversity. It arose from an observation by Pieretti and team that many biotic sounds, like birdsong, are characterized by an intrinsic variability of intensities, while many types of anthropogenic noise (like cars or airplanes passing) exhibit consistent intensity values. It was originally designed to measure the typical complexity of bird songs in a soundscape, despite the presence of persistent human-generated noise. It quantifies irregularity in sound, and assumes that this is correlated with bird song activity.\nIt is based on the difference in amplitude between one time sample and the next within a frequency band, relative to the total amplitude (Bradfer-Lawrence et al 2019). A recording is divided into a grid, an “ACI matrix”, that is made up of time sample rows and frequency band columns. ACI compares the sound intensity in each little grid square with the next one. When using ACI, you need to consider what time period and frequency bands are biologically meaningful for your survey.\nACI also requires you to specify a time step J, which is a length of time made up of a number of time samples. Number of time samples in each time step J = total number time samples / J. J thus has to do with the level of detail and amount of “smoothing” the ACI does - the more J steps there are, the larger the ACI value will be.\nAs it’s designed to quantify the inherent irregularity in biophony, it is relatively impervious to persistent sounds of constant intensity. Note that those persistent sounds could be biophonic, and insect drones are particularly prone to this. Pieretti found a significant correlation between ACI values and the number of bird vocalizations. That relationship was weaker with other acoustic indices due to interference from the airplane noise."
  },
  {
    "objectID": "posts/acoustic-indices/index.html#putting-acoustic-indices-to-use",
    "href": "posts/acoustic-indices/index.html#putting-acoustic-indices-to-use",
    "title": "What are acoustic indices?",
    "section": "Putting acoustic indices to use",
    "text": "Putting acoustic indices to use\nSeveral packages have been developed to streamline the calculation of acoustic indices. Perhaps the most widely used are the Seewave and SoundEcology packages for R. There are other options that don’t require coding, however: the Arbimon Rainforest Connection website, and interactive computer applications like Wildlife Acoustics’ Kaleidoscope\n\nMonitoring soundscapes over time\nAcoustic indices give us a way to visualize soundscapes using massive databases of recordings to look at change over time.\n\n\n\nHistogram of 13 months of recording (Phillips et al 2018)\n\n\nThis figure shows how the soundscape of a national park in Australia changes over the course of a year. Each color represents a proportion of sounds in a certain category - birds, insects, planes, rain, etc. Phillips and team made continuous recordings at a single site for 13 months (yielding ~3 TB of data). They then divided the recordings into 1 min files and calculated 12 acoustic indices for each file. The indices were then clustered to create characteristic acoustic classes which correspond to the color categories.\nThis illustrates how acoustic indices are often not used on their own, but to inform clustering or multivariate analysis that can tell a more detailed story of what is going on over time. We can learn so much if we only take the time to stop and listen!\n\nReferences\n\nSueur, J. (2018). Sound Analysis and Synthesis with R. Springer eBook. https://doi.org/10.1007/978-3-319-77647-7\nKrause, Bernie. (1993). The Niche Hypothesis: A virtual symphony of animal sounds, the origins of musical expression and the health of habitats. Soundscape Newsletter (World Forum for Acoustic Ecology).\nBradfer-Lawrence, T., Gardner, N., Bunnefeld, L., Bunnefeld, N., Willis, S.G. & Dent, D.H. (2019) Guidelines for the use of acoustic indices in environmental research. Methods Ecol Evol, 10, 1796-1807. https ://doi.org/10.1111/2041- 210X.13254\nBoelman, N., Asner, G., Hart, P. & Martin, R. (2007). Multi-trophic invasion resistance in Hawaii: Bioacoustics, field surveys, and airborne remote sensing. Ecological Applications, 17, 2137–2144. https ://doi. org/10.1890/07-0004.1\nKasten, E., Gage, S., Fox, J. & Joo, W. (2012). The remote environmental assessment laboratory’s acoustic library: An archive for studying soundscape ecology. Ecological Informatics, 12, 50–67. https ://doi.org/10.1016/j.ecoinf.2012.08.001\nGage, S. & Axel, A. (2014). Visualization of temporal change in soundscape power of a Michigan lake habitat over a 4-year period. Ecological Informatics 21 (2014) 100–109\nPijanowski, B. C., Villanueva-Rivera, L. J., Dumyahn, S. L., Farina, A., Krause, B. L., Napoletano, B. M., & Pieretti, N. (2011). Soundscape ecology: The science of sound in the landscape. BioScience, 61, 203–216. https ://doi.org/10.1525/bio.2011.61.3.6\nVillanueva-Rivera, L., Pijanowski, B., Doucette, J., & Pekin, B. (2011). A primer of acoustic analysis for landscape ecologists. Landscape Ecology, 26, 1233–1246. https ://doi.org/10.1007/s10980-011-9636-9\nPhillips, YF., Towsey, M. and Roe, P. (2018) Revealing the ecological content of long duration audio-recordings of the environment through clustering and visualisation. PLoS ONE 13(3): e0193345. https://doi.org/10.1371/journal.pone.0193345\nPieretti, N., Farina, A. & Morri, D. (2011). A new methodology to infer the singing activity of an avian community: The Acoustic Complexity Index (ACI). Ecological Indicators, 11, 868– 873. https :// doi.org/10.1016/j.ecoli nd.2010.11.005\nTattersall, F, Howden-Leach, P. Introduction to Acoustic Indices for Biodiversity Monitoring. Wildlife Acoustics webinar, February 2023."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "quarto-blog-demo",
    "section": "",
    "text": "analysis\n\n\n\n\n\n\n\n\n\n\n\nMar 2, 2023\n\n\nGio Jacuzzi\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  }
]